{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee08b81-5a14-495a-90fe-e3074bf2a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import goslate\n",
    "import glob\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6dce03-6ab7-4135-b117-5a45e02b96f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/niravjivani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/niravjivani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "snow = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affe961d-aa84-44b9-87c8-6678facf2cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(texts): \n",
    "    final_text_list=[]\n",
    "    #gs = goslate.Goslate()    \n",
    "    for sent in texts:\n",
    "        \n",
    "        # Check if the sentence is a missing value\n",
    "        if isinstance(sent, str) == False:\n",
    "            sent = ''\n",
    "        # translate any language to English\n",
    "        # Define a delay between requests (in seconds)\n",
    "        #request_delay = 1 \n",
    "        \n",
    "        #sent = gs.translate(sent, 'en')\n",
    "        #print(sent)\n",
    "        #time.sleep(request_delay)  # Introduce a delay between requests\n",
    "        filtered_sentence=[]\n",
    "        sent = sent.lower() # Lowercase \n",
    "        sent = sent.strip() # Remove leading/trailing whitespace\n",
    "        sent = re.sub('\\s+', ' ', sent) # Remove extra space and tabs\n",
    "        sent = re.compile('<.*?>').sub('', sent) # Remove HTML tags/markups:\n",
    "        for w in word_tokenize(sent):\n",
    "            # Applying some custom filtering here, feel free to try different things\n",
    "            # Check if it is not numeric and its length>2 and not in stopwords\n",
    "            if(not w.isnumeric()) and (len(w)>2) and (w not in stop):  \n",
    "                # Stem and add to filtered list\n",
    "                filtered_sentence.append(snow.stem(w))\n",
    "        final_string = \" \".join(filtered_sentence) # Final string of cleaned words\n",
    " \n",
    "        final_text_list.append(final_string)\n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0fcea82-c912-4409-afa3-d4570d35eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model and tokenizer\n",
    "output_model_path = \"./bert_paraphrase_model\"\n",
    "tokenizer = BertTokenizer.from_pretrained(output_model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(output_model_path)\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "input_data = pd.DataFrame({\n",
    "    'sentence1': ['Historical monuments and memorials endure as symbols of shared and collective memory and identity, embodying the stories, values, and hopes of societies across eras. Beyond safeguarding cultural heritage, these structures ignite introspection, dialogue, and contestation. Preserving their integrity amidst evolving societal, political, and environmental landscapes presents multifaceted challenges, necessitating nuanced approaches that balance conservation with inclusivity and contextual reinterpretation.  At the crossroads of memory, power, and heritage, these landmarks serve as arenas for negotiation, revealing the ongoing struggles for acknowledgment, representation, and reconciliation within society. Controversies surrounding certain monuments reveal the complexities web of memory politics, reflecting divergent viewpoints on history, selfhood, and dynamics power. By critically  examination of these dynamics , we gain insight into the memory’s constructions and the quest for historical veracity and justice in today’s discourse.'],\n",
    "    'sentence2': ['Cricket is my favourite game of all other outdoor games in India. I used to play cricket in front of my house in the park with my school friends and neighbors. Cricket is a game that originated in British Empire (an English origin) however started playing in many countries. We need a bat and a ball to play this game. The cricket game came into vogue and gained popularity by the 18th century. There are two teams in cricket with 11 players in each, and two umpires to notice the faults according to the law and judge all the fair and unfair while playing the cricket. Before starting the game, a coin is tossed by the team’s captain to decide which team starts batting first and the other one bowling.Both of the teams get the chance to bat alternatively. However, the team that wins the toss does batting first, and the opposite team do bowling. Cricket has become one of the fascinating games in India from the observers’ point of view. When any national or international level cricket game is fixed to play, highly interested people become so excited a week before the start of the game. Many cricket lovers start booking tickets to see them live and on-site cricket games in the stadium instead of seeing them on TV or the news. Our country has become one of the most famous countries in cricket playing all over the world. Many times India has won the world cup and many test matches.'],\n",
    "    'label': [2]  # Dummy labels for testing\n",
    "})\n",
    "input_data['sentence1'] = process_text(input_data['sentence1'])\n",
    "input_data['sentence2'] = process_text(input_data['sentence2'])\n",
    "# Prepare input tensors\n",
    "inputs = tokenizer(\n",
    "    input_data['sentence1'].tolist(), \n",
    "    input_data['sentence2'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "input_ids = inputs[\"input_ids\"].to(device)\n",
    "attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "# Output the predictions\n",
    "print(\"Predicted labels:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fc6fa-817f-4cb7-bfd1-4c7b479a9a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47088496-7ec7-4f24-95ae-335d8d83a7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
