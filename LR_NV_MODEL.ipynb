{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1063057e-2c7b-459f-a14d-7ebf2a8f4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import goslate\n",
    "import glob\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66a41e1b-54e7-4976-81ab-80e169bfbc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data for dev stored to dev.csv with shape: (2000, 3)\n",
      "Filtered data for test stored to test.csv with shape: (2000, 3)\n",
      "Filtered data for train stored to train.csv with shape: (49184, 3)\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a value is a number\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Iterate over each PART\n",
    "for PART in ['dev', 'test', 'train']:\n",
    "    # Get a list of files for the current PART\n",
    "    files = glob.glob(f'./{PART}_*.csv', recursive=True)\n",
    "    \n",
    "    # List to store filtered rows\n",
    "    filtered_rows = []\n",
    "    \n",
    "    # Iterate over each file for the current PART\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Iterate over each row of the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            row = row[1:4]\n",
    "            \n",
    "            # Check if the last column contains a number\n",
    "            if is_number(row.iloc[-1]):\n",
    "                # Append the row to the list\n",
    "                filtered_rows.append(row)\n",
    "    \n",
    "    # Create a new DataFrame from the list of filtered rows\n",
    "    new_df = pd.DataFrame(filtered_rows)\n",
    "    \n",
    "    # Determine the output filename\n",
    "    output_filename = f'{PART}.csv'\n",
    "    \n",
    "    # Store the new DataFrame to a separate filtered CSV file\n",
    "    new_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    # Print the shape of the new DataFrame\n",
    "    print(f\"Filtered data for {PART} stored to {output_filename} with shape:\", new_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b58a0e7d-ccb3-4f52-ac9d-36a84800c163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Paris , in October 1560 , he secretly met t...</td>\n",
       "      <td>In October 1560 , he secretly met with the Eng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The NBA season of 1975 -- 76 was the 30th seas...</td>\n",
       "      <td>The 1975 -- 76 season of the National Basketba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are also specific discussions , public p...</td>\n",
       "      <td>There are also public discussions , profile sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When comparable rates of flow can be maintaine...</td>\n",
       "      <td>The results are high when comparable flow rate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is the seat of Zerendi District in Akmola R...</td>\n",
       "      <td>It is the seat of the district of Zerendi in A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  In Paris , in October 1560 , he secretly met t...   \n",
       "1  The NBA season of 1975 -- 76 was the 30th seas...   \n",
       "2  There are also specific discussions , public p...   \n",
       "3  When comparable rates of flow can be maintaine...   \n",
       "4  It is the seat of Zerendi District in Akmola R...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  In October 1560 , he secretly met with the Eng...      0  \n",
       "1  The 1975 -- 76 season of the National Basketba...      1  \n",
       "2  There are also public discussions , profile sp...      0  \n",
       "3  The results are high when comparable flow rate...      1  \n",
       "4  It is the seat of the district of Zerendi in A...      1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train['label'] = train['label'].fillna(0).astype(int)\n",
    "train = train.dropna()\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b44c16bf-aa8d-4ec1-bd85-d66b153076e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The exception was between late 2005 and 2009 w...</td>\n",
       "      <td>The exception was between late 2005 and 2009 ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Tabaci River is a tributary of the River L...</td>\n",
       "      <td>The Leurda River is a tributary of the River T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He played with the A-level Kane County Cougars...</td>\n",
       "      <td>He played in 1993 with the A - Level Portland ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winarsky is a member of the IEEE , Phi Beta Ka...</td>\n",
       "      <td>Winarsky is a member of ACM , the IEEE , the P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In 1938 he became the government anthropologis...</td>\n",
       "      <td>In 1938 he became the Government Anthropologis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  The exception was between late 2005 and 2009 w...   \n",
       "1  The Tabaci River is a tributary of the River L...   \n",
       "2  He played with the A-level Kane County Cougars...   \n",
       "3  Winarsky is a member of the IEEE , Phi Beta Ka...   \n",
       "4  In 1938 he became the government anthropologis...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  The exception was between late 2005 and 2009 ,...      1  \n",
       "1  The Leurda River is a tributary of the River T...      0  \n",
       "2  He played in 1993 with the A - Level Portland ...      0  \n",
       "3  Winarsky is a member of ACM , the IEEE , the P...      1  \n",
       "4  In 1938 he became the Government Anthropologis...      0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cfd28e5d-98bf-4a8a-9d0a-e2de2a1d4a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From the merger of the Four Rivers Council and...</td>\n",
       "      <td>Shawnee Trails Council was formed from the mer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kathy and her husband Pete Beale ( Peter Dean ...</td>\n",
       "      <td>Kathy and her husband Peter Dean ( Pete Beale ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Timora diarhoda is a species of moth of the No...</td>\n",
       "      <td>Diarhoda is a kind of moth of the Noctuidae fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joe R. Campa Jr. is a former sailor of the Uni...</td>\n",
       "      <td>Joe R. Campa Jr. is a former U.S. Navy Matrose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cook Pond , also known as the South Watuppa Po...</td>\n",
       "      <td>Cook Pond , also formerly known as Laurel Lake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  From the merger of the Four Rivers Council and...   \n",
       "1  Kathy and her husband Pete Beale ( Peter Dean ...   \n",
       "2  Timora diarhoda is a species of moth of the No...   \n",
       "3  Joe R. Campa Jr. is a former sailor of the Uni...   \n",
       "4  Cook Pond , also known as the South Watuppa Po...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  Shawnee Trails Council was formed from the mer...      1  \n",
       "1  Kathy and her husband Peter Dean ( Pete Beale ...      1  \n",
       "2  Diarhoda is a kind of moth of the Noctuidae fa...      1  \n",
       "3  Joe R. Campa Jr. is a former U.S. Navy Matrose...      1  \n",
       "4  Cook Pond , also formerly known as Laurel Lake...      0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv(\"dev.csv\")\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3cff1a50-9e29-4d8d-a957-a19d21c532c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence1    object\n",
       "sentence2    object\n",
       "label         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34c2c479-c0b8-4738-938c-0478d50bf832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/niravjivani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/niravjivani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "snow = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "803f01a3-4333-4617-a615-8f6f83c0d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(texts): \n",
    "    final_text_list=[]\n",
    "    #gs = goslate.Goslate()    \n",
    "    for sent in texts:\n",
    "        \n",
    "        # Check if the sentence is a missing value\n",
    "        if isinstance(sent, str) == False:\n",
    "            sent = ''\n",
    "\n",
    "        # translate any language to English\n",
    "        # sent = gs.translate(sent, 'en')\n",
    "        filtered_sentence=[]\n",
    "        sent = sent.lower() # Lowercase \n",
    "        sent = sent.strip() # Remove leading/trailing whitespace\n",
    "        sent = re.sub('\\s+', ' ', sent) # Remove extra space and tabs\n",
    "        sent = re.compile('<.*?>').sub('', sent) # Remove HTML tags/markups:\n",
    "        for w in word_tokenize(sent):\n",
    "            # Applying some custom filtering here, feel free to try different things\n",
    "            # Check if it is not numeric and its length>2 and not in stopwords\n",
    "            if(not w.isnumeric()) and (len(w)>2) and (w not in stop):  \n",
    "                # Stem and add to filtered list\n",
    "                filtered_sentence.append(snow.stem(w))\n",
    "        final_string = \" \".join(filtered_sentence) # Final string of cleaned words\n",
    " \n",
    "        final_text_list.append(final_string)\n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29c03871-e6bf-4d1e-920f-ab40878d0df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train[['sentence1', 'sentence2']],\n",
    "                                                  train['label'],\n",
    "                                                  test_size=0.10,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=324\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bbe51f03-ba1d-4df6-9454-9acd142e8cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the sentence1 fields\n",
      "Processing the sentence2 fields\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "09ac1883-b81c-45d2-9295-74e638f5c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['sentence1', 'sentence2']\n",
    "\n",
    "model_features = text_features\n",
    "model_target = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c476799-76e8-49c9-85b9-1e32c8f97515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets shapes before processing:  (44265, 2) (4919, 2) (2000, 3)\n",
      "Datasets shapes after processing:  (44265, 200) (4919, 200) (2000, 200)\n"
     ]
    }
   ],
   "source": [
    "X_test=test\n",
    "X_train['sentence1'] = process_text(X_train['sentence1'].tolist())\n",
    "X_val['sentence1'] = process_text(X_val['sentence1'].tolist())\n",
    "X_test['sentence1'] = process_text(test['sentence1'].tolist())\n",
    "\n",
    "X_train['sentence2'] = process_text(X_train['sentence2'].tolist())\n",
    "X_val['sentence2'] = process_text(X_val['sentence2'].tolist())\n",
    "X_test['sentence2'] = process_text(test['sentence2'].tolist())\n",
    "### COLUMN_TRANSFORMER ###\n",
    "##########################\n",
    "text_processor_0 = Pipeline([\n",
    "    ('text_vect_0', CountVectorizer(binary=True, max_features=100))\n",
    "                                ])\n",
    "text_precessor_1 = Pipeline([\n",
    "    ('text_vect_1', CountVectorizer(binary=True, max_features=100))\n",
    "                                ])\n",
    "data_preprocessor = ColumnTransformer([\n",
    "    ('text_pre_0', text_processor_0, text_features[0]),\n",
    "    ('text_pre_1', text_precessor_1, text_features[1])\n",
    "                                    ]) \n",
    "### DATA PREPROCESSING ###\n",
    "##########################\n",
    "print('Datasets shapes before processing: ', X_train.shape, X_val.shape, X_test.shape)\n",
    "X_train = data_preprocessor.fit_transform(X_train).toarray()\n",
    "X_val = data_preprocessor.transform(X_val).toarray()\n",
    "X_test = data_preprocessor.transform(X_test).toarray()\n",
    "print('Datasets shapes after processing: ', X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53847361-fff6-4db0-9867-d5c5504db026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df13260b-58a5-4c38-902f-be009364d829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5556007318560683\n"
     ]
    }
   ],
   "source": [
    "# Get the indices of NaN values in y_train\n",
    "nan_indices = np.argwhere(np.isnan(y_train)).flatten()\n",
    "\n",
    "# Remove corresponding rows from X_train\n",
    "X_train = np.delete(X_train, nan_indices, axis=0)\n",
    "# Remove NaN values from y_train\n",
    "y_train = np.delete(y_train, nan_indices)\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "val_predictions = model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, val_predictions))\n",
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f798da8-e052-4f4a-a1f3-d1983748f184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5436064240699329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Define Multinomial Naive Bayes model\n",
    "nlp_model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_predictions = nlp_model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, val_predictions))\n",
    "\n",
    "# Predict on test set\n",
    "test_predictions = nlp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073ca10-064d-4478-98c0-f198b7d0f1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
